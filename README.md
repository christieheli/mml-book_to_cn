# mml-book_to_cn
mml-book 机器学习的数学翻译

**书目录：**

- 前言 1
- 第一部分 数学基础 9
- 1 介绍与动机 11
  - 1.1 为直觉寻找语言 12
  - 1.2 阅读本书的两种方法 13
  - 1.3 练习与反馈 16
- 2 线性代数 17
  - 2.1 线性方程组 19
  - 2.2 矩阵 22
  - 2.3 求解线性方程组 27
  - 2.4 向量空间 35
  - 2.5 线性无关 40
  - 2.6 基和秩 44
  - 2.7 线性映射 48
  - 2.8 仿射空间 61
  - 2.9 延伸阅读 63
  - 练习 64
- 3 解析几何 70
  - 3.1 范数 71
  - 3.2 内积 72
  - 3.3 长度和距离 75
  - 3.4 角度和正交性 76
  - 3.5 正交基 78
  - 3.6 正交补 79
  - 3.7 函数的内积 80
  - 3.8 正交投影 81
  - 3.9 旋转 91
  - 3.10 延伸阅读 94
  - 练习 96
- 4 矩阵分解 98
  - 4.1 行列式和迹 99
  - 4.2 特征值和特征向量 105
  - 4.3 乔里斯基分解 114
  - 4.4 特征分解和对角化 115
  - 4.5 奇异值分解 119
  - 4.6 矩阵近似 129
  - 4.7 矩阵系统发育 134
  - 4.8 延伸阅读 135
  - 练习 137
- 5 向量微积分 139
  - 5.1 单变量函数的微分 141
  - 5.2 偏微分和梯度 146
  - 5.3 向量值函数的梯度 149
  - 5.4 矩阵的梯度 155
  - 5.5 计算梯度的有用恒等式 158
  - 5.6 反向传播和自动微分 159
  - 5.7 高阶导数 164
  - 5.8 线性化和多元泰勒级数 165
  - 5.9 延伸阅读 170
  - 练习 170
- 6 概率与分布 172
  - 6.1 概率空间的构造 172
  - 6.2 离散概率和连续概率 178
  - 6.3 求和规则、乘积规则和贝叶斯定理 183
  - 6.4 汇总统计和独立性 186
  - 6.5 高斯分布 197
  - 6.6 共轭性和指数族 205
  - 6.7 变量变换/逆变换 214
  - 6.8 延伸阅读 221
  - 练习 222
- 7 连续优化 225
  - 7.1 使用梯度下降进行优化 227
  - 7.2 约束优化和拉格朗日乘数 233
  - 7.3 凸优化 236
  - 7.4 延伸阅读 246
  - 练习 247
- 第二部分 核心机器学习问题 249
- 8 当模型遇到数据 251
  - 8.1 数据、模型和学习 251
  - 8.2 经验风险最小化 258
  - 8.3 参数估计 265
  - 8.4 概率建模和推理 272
  - 8.5 有向图模型 278
  - 8.6 模型选择 283
- 9 线性回归 289
  - 9.1 问题公式 291
  - 9.2 参数估计 292
  - 9.3 贝叶斯线性回归 303
  - 9.4 最大似然作为正交投影 313
  - 9.5 延伸阅读 315
- 10 使用主成分分析进行降维 317
  - 10.1 问题设置 318
  - 10.2 最大方差视角 320
  - 10.3 投影视角 325
  - 10.4 特征向量计算和低秩近似 333
  - 10.5 高维 PCA 335
  - 10.6 实践中 PCA 的关键步骤 336
  - 10.7 潜变量视角 339
  - 10.8 延伸阅读 343
- 11 使用高斯混合模型进行密度估计 348
  - 11.1 高斯混合模型 349
  - 11.2 通过最大似然估计进行参数学习 350
  - 11.3 EM 算法 360
  - 11.4 潜变量视角 363
  - 11.5 延伸阅读 368
- 12 使用支持向量机进行分类 370
  - 12.1 分离超平面 372
  - 12.2 原始支持向量机 374
  - 12.3 对偶支持向量机 383
  - 12.4 核 388
  - 12.5 数值解 390
  - 12.6 延伸阅读 392
- 参考文献 395
- 索 407
